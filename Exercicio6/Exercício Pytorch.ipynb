{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício sobre pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize o dataset 'datasetCarros.csv'.<br>\n",
    "Usando Pytorch, construa uma rede neural para prever a feature 'PrecoVenda'.<br>\n",
    "\n",
    "Use uma rede neural feed forward com duas camadas escondidas, com 20 neurônios cada.<br>\n",
    "Use o critério de perda MSELoss, otimizador Adam e learning rate = 0.001. Considere 1000 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([301])\n",
      "torch.Size([301, 6])\n",
      "torch.Size([270, 6])\n",
      "torch.Size([270])\n",
      "Feedforward(\n",
      "  (fc1): Linear(in_features=6, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc4): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Teste - perda antes do treinamento 24011.2265625\n",
      "Epoch 0: perda treino: 17933.615234375\n",
      "Epoch 1: perda treino: 5058.1923828125\n",
      "Epoch 2: perda treino: 483.6993103027344\n",
      "Epoch 3: perda treino: 591.071044921875\n",
      "Epoch 4: perda treino: 2400.69775390625\n",
      "Epoch 5: perda treino: 3704.972412109375\n",
      "Epoch 6: perda treino: 3762.849609375\n",
      "Epoch 7: perda treino: 2859.634033203125\n",
      "Epoch 8: perda treino: 1619.340087890625\n",
      "Epoch 9: perda treino: 602.5738525390625\n",
      "Epoch 10: perda treino: 133.784912109375\n",
      "Epoch 11: perda treino: 245.53143310546875\n",
      "Epoch 12: perda treino: 717.8212890625\n",
      "Epoch 13: perda treino: 1215.9462890625\n",
      "Epoch 14: perda treino: 1468.7188720703125\n",
      "Epoch 15: perda treino: 1380.5963134765625\n",
      "Epoch 16: perda treino: 1030.08642578125\n",
      "Epoch 17: perda treino: 592.4287109375\n",
      "Epoch 18: perda treino: 246.64060974121094\n",
      "Epoch 19: perda treino: 103.51949310302734\n",
      "Epoch 20: perda treino: 170.9553985595703\n",
      "Epoch 21: perda treino: 364.8211669921875\n",
      "Epoch 22: perda treino: 559.0244140625\n",
      "Epoch 23: perda treino: 649.8980102539062\n",
      "Epoch 24: perda treino: 600.4264526367188\n",
      "Epoch 25: perda treino: 445.7347412109375\n",
      "Epoch 26: perda treino: 270.29449462890625\n",
      "Epoch 27: perda treino: 132.02207946777344\n",
      "Epoch 28: perda treino: 95.33666229248047\n",
      "Epoch 29: perda treino: 145.88034057617188\n",
      "Epoch 30: perda treino: 236.6723175048828\n",
      "Epoch 31: perda treino: 309.6173095703125\n",
      "Epoch 32: perda treino: 325.23016357421875\n",
      "Epoch 33: perda treino: 279.35357666015625\n",
      "Epoch 34: perda treino: 199.20736694335938\n",
      "Epoch 35: perda treino: 125.14463806152344\n",
      "Epoch 36: perda treino: 87.99281311035156\n",
      "Epoch 37: perda treino: 96.02536010742188\n",
      "Epoch 38: perda treino: 133.0343475341797\n",
      "Epoch 39: perda treino: 170.5179901123047\n",
      "Epoch 40: perda treino: 184.900634765625\n",
      "Epoch 41: perda treino: 168.59461975097656\n",
      "Epoch 42: perda treino: 131.63739013671875\n",
      "Epoch 43: perda treino: 93.59904479980469\n",
      "Epoch 44: perda treino: 70.81951904296875\n",
      "Epoch 45: perda treino: 67.68424987792969\n",
      "Epoch 46: perda treino: 76.03715515136719\n",
      "Epoch 47: perda treino: 78.99976348876953\n",
      "Epoch 48: perda treino: 60.193092346191406\n",
      "Epoch 49: perda treino: 40.47972869873047\n",
      "Epoch 50: perda treino: 70.0870132446289\n",
      "Epoch 51: perda treino: 52.58815383911133\n",
      "Epoch 52: perda treino: 41.328025817871094\n",
      "Epoch 53: perda treino: 50.442081451416016\n",
      "Epoch 54: perda treino: 56.12726593017578\n",
      "Epoch 55: perda treino: 49.10600662231445\n",
      "Epoch 56: perda treino: 37.74033737182617\n",
      "Epoch 57: perda treino: 36.01803207397461\n",
      "Epoch 58: perda treino: 41.890464782714844\n",
      "Epoch 59: perda treino: 41.206809997558594\n",
      "Epoch 60: perda treino: 34.31709671020508\n",
      "Epoch 61: perda treino: 31.031734466552734\n",
      "Epoch 62: perda treino: 32.993133544921875\n",
      "Epoch 63: perda treino: 35.597442626953125\n",
      "Epoch 64: perda treino: 35.182254791259766\n",
      "Epoch 65: perda treino: 32.74514389038086\n",
      "Epoch 66: perda treino: 30.930377960205078\n",
      "Epoch 67: perda treino: 31.368316650390625\n",
      "Epoch 68: perda treino: 32.7591552734375\n",
      "Epoch 69: perda treino: 32.6110954284668\n",
      "Epoch 70: perda treino: 30.655324935913086\n",
      "Epoch 71: perda treino: 28.843841552734375\n",
      "Epoch 72: perda treino: 28.55908966064453\n",
      "Epoch 73: perda treino: 29.164602279663086\n",
      "Epoch 74: perda treino: 29.169973373413086\n",
      "Epoch 75: perda treino: 27.856828689575195\n",
      "Epoch 76: perda treino: 26.74199676513672\n",
      "Epoch 77: perda treino: 26.89158821105957\n",
      "Epoch 78: perda treino: 27.727699279785156\n",
      "Epoch 79: perda treino: 27.53389549255371\n",
      "Epoch 80: perda treino: 26.544769287109375\n",
      "Epoch 81: perda treino: 26.528974533081055\n",
      "Epoch 82: perda treino: 27.1012020111084\n",
      "Epoch 83: perda treino: 26.868602752685547\n",
      "Epoch 84: perda treino: 26.234142303466797\n",
      "Epoch 85: perda treino: 26.29114532470703\n",
      "Epoch 86: perda treino: 26.653831481933594\n",
      "Epoch 87: perda treino: 26.462955474853516\n",
      "Epoch 88: perda treino: 26.085405349731445\n",
      "Epoch 89: perda treino: 26.186140060424805\n",
      "Epoch 90: perda treino: 26.424705505371094\n",
      "Epoch 91: perda treino: 26.279796600341797\n",
      "Epoch 92: perda treino: 26.052034378051758\n",
      "Epoch 93: perda treino: 26.14756202697754\n",
      "Epoch 94: perda treino: 26.296730041503906\n",
      "Epoch 95: perda treino: 26.182270050048828\n",
      "Epoch 96: perda treino: 26.0452880859375\n",
      "Epoch 97: perda treino: 26.125980377197266\n",
      "Epoch 98: perda treino: 26.209354400634766\n",
      "Epoch 99: perda treino: 26.114999771118164\n",
      "Epoch 100: perda treino: 26.034221649169922\n",
      "Epoch 101: perda treino: 26.098432540893555\n",
      "Epoch 102: perda treino: 26.137178421020508\n",
      "Epoch 103: perda treino: 26.059995651245117\n",
      "Epoch 104: perda treino: 26.017736434936523\n",
      "Epoch 105: perda treino: 26.066495895385742\n",
      "Epoch 106: perda treino: 26.07460594177246\n",
      "Epoch 107: perda treino: 26.013723373413086\n",
      "Epoch 108: perda treino: 25.996540069580078\n",
      "Epoch 109: perda treino: 26.029176712036133\n",
      "Epoch 110: perda treino: 26.017250061035156\n",
      "Epoch 111: perda treino: 25.97252082824707\n",
      "Epoch 112: perda treino: 25.97108268737793\n",
      "Epoch 113: perda treino: 25.988670349121094\n",
      "Epoch 114: perda treino: 25.96759033203125\n",
      "Epoch 115: perda treino: 25.940393447875977\n",
      "Epoch 116: perda treino: 25.947574615478516\n",
      "Epoch 117: perda treino: 25.95282554626465\n",
      "Epoch 118: perda treino: 25.931419372558594\n",
      "Epoch 119: perda treino: 25.919464111328125\n",
      "Epoch 120: perda treino: 25.92786407470703\n",
      "Epoch 121: perda treino: 25.92376136779785\n",
      "Epoch 122: perda treino: 25.907291412353516\n",
      "Epoch 123: perda treino: 25.905473709106445\n",
      "Epoch 124: perda treino: 25.910049438476562\n",
      "Epoch 125: perda treino: 25.901206970214844\n",
      "Epoch 126: perda treino: 25.891948699951172\n",
      "Epoch 127: perda treino: 25.894332885742188\n",
      "Epoch 128: perda treino: 25.893535614013672\n",
      "Epoch 129: perda treino: 25.884647369384766\n",
      "Epoch 130: perda treino: 25.88150978088379\n",
      "Epoch 131: perda treino: 25.883169174194336\n",
      "Epoch 132: perda treino: 25.878572463989258\n",
      "Epoch 133: perda treino: 25.87259292602539\n",
      "Epoch 134: perda treino: 25.872451782226562\n",
      "Epoch 135: perda treino: 25.87128257751465\n",
      "Epoch 136: perda treino: 25.865829467773438\n",
      "Epoch 137: perda treino: 25.863012313842773\n",
      "Epoch 138: perda treino: 25.86268424987793\n",
      "Epoch 139: perda treino: 25.85920524597168\n",
      "Epoch 140: perda treino: 25.855112075805664\n",
      "Epoch 141: perda treino: 25.853919982910156\n",
      "Epoch 142: perda treino: 25.852067947387695\n",
      "Epoch 143: perda treino: 25.848257064819336\n",
      "Epoch 144: perda treino: 25.845979690551758\n",
      "Epoch 145: perda treino: 25.844694137573242\n",
      "Epoch 146: perda treino: 25.84174346923828\n",
      "Epoch 147: perda treino: 25.838804244995117\n",
      "Epoch 148: perda treino: 25.837263107299805\n",
      "Epoch 149: perda treino: 25.835071563720703\n",
      "Epoch 150: perda treino: 25.832107543945312\n",
      "Epoch 151: perda treino: 25.830095291137695\n",
      "Epoch 152: perda treino: 25.828306198120117\n",
      "Epoch 153: perda treino: 25.825664520263672\n",
      "Epoch 154: perda treino: 25.823341369628906\n",
      "Epoch 155: perda treino: 25.821598052978516\n",
      "Epoch 156: perda treino: 25.819355010986328\n",
      "Epoch 157: perda treino: 25.816965103149414\n",
      "Epoch 158: perda treino: 25.815105438232422\n",
      "Epoch 159: perda treino: 25.813140869140625\n",
      "Epoch 160: perda treino: 25.810842514038086\n",
      "Epoch 161: perda treino: 25.808879852294922\n",
      "Epoch 162: perda treino: 25.807048797607422\n",
      "Epoch 163: perda treino: 25.804906845092773\n",
      "Epoch 164: perda treino: 25.80286979675293\n",
      "Epoch 165: perda treino: 25.801050186157227\n",
      "Epoch 166: perda treino: 25.799060821533203\n",
      "Epoch 167: perda treino: 25.797012329101562\n",
      "Epoch 168: perda treino: 25.795175552368164\n",
      "Epoch 169: perda treino: 25.793289184570312\n",
      "Epoch 170: perda treino: 25.79130744934082\n",
      "Epoch 171: perda treino: 25.789451599121094\n",
      "Epoch 172: perda treino: 25.78765106201172\n",
      "Epoch 173: perda treino: 25.785751342773438\n",
      "Epoch 174: perda treino: 25.783916473388672\n",
      "Epoch 175: perda treino: 25.78215789794922\n",
      "Epoch 176: perda treino: 25.78032684326172\n",
      "Epoch 177: perda treino: 25.778514862060547\n",
      "Epoch 178: perda treino: 25.776790618896484\n",
      "Epoch 179: perda treino: 25.775028228759766\n",
      "Epoch 180: perda treino: 25.773263931274414\n",
      "Epoch 181: perda treino: 25.771560668945312\n",
      "Epoch 182: perda treino: 25.769855499267578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([270])) that is different to the input size (torch.Size([270, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183: perda treino: 25.768131256103516\n",
      "Epoch 184: perda treino: 25.766454696655273\n",
      "Epoch 185: perda treino: 25.764802932739258\n",
      "Epoch 186: perda treino: 25.763120651245117\n",
      "Epoch 187: perda treino: 25.761472702026367\n",
      "Epoch 188: perda treino: 25.759855270385742\n",
      "Epoch 189: perda treino: 25.758224487304688\n",
      "Epoch 190: perda treino: 25.756608963012695\n",
      "Epoch 191: perda treino: 25.755020141601562\n",
      "Epoch 192: perda treino: 25.753433227539062\n",
      "Epoch 193: perda treino: 25.75185775756836\n",
      "Epoch 194: perda treino: 25.750308990478516\n",
      "Epoch 195: perda treino: 25.74875831604004\n",
      "Epoch 196: perda treino: 25.747222900390625\n",
      "Epoch 197: perda treino: 25.745704650878906\n",
      "Epoch 198: perda treino: 25.744197845458984\n",
      "Epoch 199: perda treino: 25.74268913269043\n",
      "Epoch 200: perda treino: 25.741209030151367\n",
      "Epoch 201: perda treino: 25.739736557006836\n",
      "Epoch 202: perda treino: 25.73826789855957\n",
      "Epoch 203: perda treino: 25.736820220947266\n",
      "Epoch 204: perda treino: 25.735382080078125\n",
      "Epoch 205: perda treino: 25.733951568603516\n",
      "Epoch 206: perda treino: 25.73253631591797\n",
      "Epoch 207: perda treino: 25.731130599975586\n",
      "Epoch 208: perda treino: 25.729734420776367\n",
      "Epoch 209: perda treino: 25.728347778320312\n",
      "Epoch 210: perda treino: 25.726974487304688\n",
      "Epoch 211: perda treino: 25.725616455078125\n",
      "Epoch 212: perda treino: 25.724262237548828\n",
      "Epoch 213: perda treino: 25.722925186157227\n",
      "Epoch 214: perda treino: 25.721595764160156\n",
      "Epoch 215: perda treino: 25.720273971557617\n",
      "Epoch 216: perda treino: 25.718961715698242\n",
      "Epoch 217: perda treino: 25.717674255371094\n",
      "Epoch 218: perda treino: 25.716392517089844\n",
      "Epoch 219: perda treino: 25.715120315551758\n",
      "Epoch 220: perda treino: 25.713865280151367\n",
      "Epoch 221: perda treino: 25.712608337402344\n",
      "Epoch 222: perda treino: 25.711374282836914\n",
      "Epoch 223: perda treino: 25.71014404296875\n",
      "Epoch 224: perda treino: 25.70892906188965\n",
      "Epoch 225: perda treino: 25.707725524902344\n",
      "Epoch 226: perda treino: 25.70652961730957\n",
      "Epoch 227: perda treino: 25.705347061157227\n",
      "Epoch 228: perda treino: 25.704172134399414\n",
      "Epoch 229: perda treino: 25.703006744384766\n",
      "Epoch 230: perda treino: 25.70184898376465\n",
      "Epoch 231: perda treino: 25.700706481933594\n",
      "Epoch 232: perda treino: 25.699575424194336\n",
      "Epoch 233: perda treino: 25.69844627380371\n",
      "Epoch 234: perda treino: 25.697330474853516\n",
      "Epoch 235: perda treino: 25.696224212646484\n",
      "Epoch 236: perda treino: 25.695127487182617\n",
      "Epoch 237: perda treino: 25.69404411315918\n",
      "Epoch 238: perda treino: 25.69295883178711\n",
      "Epoch 239: perda treino: 25.691890716552734\n",
      "Epoch 240: perda treino: 25.690834045410156\n",
      "Epoch 241: perda treino: 25.689783096313477\n",
      "Epoch 242: perda treino: 25.68874168395996\n",
      "Epoch 243: perda treino: 25.687705993652344\n",
      "Epoch 244: perda treino: 25.68667984008789\n",
      "Epoch 245: perda treino: 25.685667037963867\n",
      "Epoch 246: perda treino: 25.68465805053711\n",
      "Epoch 247: perda treino: 25.68366241455078\n",
      "Epoch 248: perda treino: 25.682674407958984\n",
      "Epoch 249: perda treino: 25.681690216064453\n",
      "Epoch 250: perda treino: 25.68071937561035\n",
      "Epoch 251: perda treino: 25.67975425720215\n",
      "Epoch 252: perda treino: 25.678800582885742\n",
      "Epoch 253: perda treino: 25.6778564453125\n",
      "Epoch 254: perda treino: 25.676910400390625\n",
      "Epoch 255: perda treino: 25.675983428955078\n",
      "Epoch 256: perda treino: 25.675058364868164\n",
      "Epoch 257: perda treino: 25.674142837524414\n",
      "Epoch 258: perda treino: 25.673236846923828\n",
      "Epoch 259: perda treino: 25.672338485717773\n",
      "Epoch 260: perda treino: 25.671443939208984\n",
      "Epoch 261: perda treino: 25.670564651489258\n",
      "Epoch 262: perda treino: 25.669689178466797\n",
      "Epoch 263: perda treino: 25.6688232421875\n",
      "Epoch 264: perda treino: 25.667959213256836\n",
      "Epoch 265: perda treino: 25.6671085357666\n",
      "Epoch 266: perda treino: 25.66626739501953\n",
      "Epoch 267: perda treino: 25.66543197631836\n",
      "Epoch 268: perda treino: 25.664609909057617\n",
      "Epoch 269: perda treino: 25.663795471191406\n",
      "Epoch 270: perda treino: 25.662986755371094\n",
      "Epoch 271: perda treino: 25.662187576293945\n",
      "Epoch 272: perda treino: 25.661399841308594\n",
      "Epoch 273: perda treino: 25.660614013671875\n",
      "Epoch 274: perda treino: 25.659841537475586\n",
      "Epoch 275: perda treino: 25.659074783325195\n",
      "Epoch 276: perda treino: 25.658323287963867\n",
      "Epoch 277: perda treino: 25.65757179260254\n",
      "Epoch 278: perda treino: 25.656829833984375\n",
      "Epoch 279: perda treino: 25.656091690063477\n",
      "Epoch 280: perda treino: 25.655364990234375\n",
      "Epoch 281: perda treino: 25.654645919799805\n",
      "Epoch 282: perda treino: 25.6539306640625\n",
      "Epoch 283: perda treino: 25.653228759765625\n",
      "Epoch 284: perda treino: 25.652528762817383\n",
      "Epoch 285: perda treino: 25.65183448791504\n",
      "Epoch 286: perda treino: 25.651155471801758\n",
      "Epoch 287: perda treino: 25.65047264099121\n",
      "Epoch 288: perda treino: 25.649803161621094\n",
      "Epoch 289: perda treino: 25.64913558959961\n",
      "Epoch 290: perda treino: 25.648473739624023\n",
      "Epoch 291: perda treino: 25.64781951904297\n",
      "Epoch 292: perda treino: 25.647171020507812\n",
      "Epoch 293: perda treino: 25.646528244018555\n",
      "Epoch 294: perda treino: 25.64588737487793\n",
      "Epoch 295: perda treino: 25.645259857177734\n",
      "Epoch 296: perda treino: 25.64463233947754\n",
      "Epoch 297: perda treino: 25.64401626586914\n",
      "Epoch 298: perda treino: 25.643402099609375\n",
      "Epoch 299: perda treino: 25.642791748046875\n",
      "Epoch 300: perda treino: 25.642189025878906\n",
      "Epoch 301: perda treino: 25.641592025756836\n",
      "Epoch 302: perda treino: 25.64099884033203\n",
      "Epoch 303: perda treino: 25.640411376953125\n",
      "Epoch 304: perda treino: 25.63983154296875\n",
      "Epoch 305: perda treino: 25.639251708984375\n",
      "Epoch 306: perda treino: 25.638683319091797\n",
      "Epoch 307: perda treino: 25.63811683654785\n",
      "Epoch 308: perda treino: 25.63755226135254\n",
      "Epoch 309: perda treino: 25.636991500854492\n",
      "Epoch 310: perda treino: 25.63644027709961\n",
      "Epoch 311: perda treino: 25.63589096069336\n",
      "Epoch 312: perda treino: 25.635345458984375\n",
      "Epoch 313: perda treino: 25.634809494018555\n",
      "Epoch 314: perda treino: 25.634273529052734\n",
      "Epoch 315: perda treino: 25.633747100830078\n",
      "Epoch 316: perda treino: 25.633222579956055\n",
      "Epoch 317: perda treino: 25.63269805908203\n",
      "Epoch 318: perda treino: 25.63218116760254\n",
      "Epoch 319: perda treino: 25.63166618347168\n",
      "Epoch 320: perda treino: 25.631162643432617\n",
      "Epoch 321: perda treino: 25.630661010742188\n",
      "Epoch 322: perda treino: 25.630163192749023\n",
      "Epoch 323: perda treino: 25.629667282104492\n",
      "Epoch 324: perda treino: 25.629180908203125\n",
      "Epoch 325: perda treino: 25.628700256347656\n",
      "Epoch 326: perda treino: 25.62821388244629\n",
      "Epoch 327: perda treino: 25.627723693847656\n",
      "Epoch 328: perda treino: 25.6271915435791\n",
      "Epoch 329: perda treino: 25.626632690429688\n",
      "Epoch 330: perda treino: 25.626049041748047\n",
      "Epoch 331: perda treino: 25.625450134277344\n",
      "Epoch 332: perda treino: 25.62483787536621\n",
      "Epoch 333: perda treino: 25.624221801757812\n",
      "Epoch 334: perda treino: 25.623607635498047\n",
      "Epoch 335: perda treino: 25.622987747192383\n",
      "Epoch 336: perda treino: 25.622365951538086\n",
      "Epoch 337: perda treino: 25.62175750732422\n",
      "Epoch 338: perda treino: 25.621152877807617\n",
      "Epoch 339: perda treino: 25.620559692382812\n",
      "Epoch 340: perda treino: 25.619977951049805\n",
      "Epoch 341: perda treino: 25.619407653808594\n",
      "Epoch 342: perda treino: 25.618850708007812\n",
      "Epoch 343: perda treino: 25.618305206298828\n",
      "Epoch 344: perda treino: 25.617774963378906\n",
      "Epoch 345: perda treino: 25.61725425720215\n",
      "Epoch 346: perda treino: 25.616756439208984\n",
      "Epoch 347: perda treino: 25.61626625061035\n",
      "Epoch 348: perda treino: 25.61577606201172\n",
      "Epoch 349: perda treino: 25.61530876159668\n",
      "Epoch 350: perda treino: 25.614849090576172\n",
      "Epoch 351: perda treino: 25.614397048950195\n",
      "Epoch 352: perda treino: 25.613962173461914\n",
      "Epoch 353: perda treino: 25.61353302001953\n",
      "Epoch 354: perda treino: 25.61311149597168\n",
      "Epoch 355: perda treino: 25.612693786621094\n",
      "Epoch 356: perda treino: 25.612287521362305\n",
      "Epoch 357: perda treino: 25.611881256103516\n",
      "Epoch 358: perda treino: 25.611480712890625\n",
      "Epoch 359: perda treino: 25.611087799072266\n",
      "Epoch 360: perda treino: 25.610702514648438\n",
      "Epoch 361: perda treino: 25.610321044921875\n",
      "Epoch 362: perda treino: 25.60994529724121\n",
      "Epoch 363: perda treino: 25.609575271606445\n",
      "Epoch 364: perda treino: 25.609207153320312\n",
      "Epoch 365: perda treino: 25.608842849731445\n",
      "Epoch 366: perda treino: 25.608484268188477\n",
      "Epoch 367: perda treino: 25.60812759399414\n",
      "Epoch 368: perda treino: 25.60777473449707\n",
      "Epoch 369: perda treino: 25.607421875\n",
      "Epoch 370: perda treino: 25.607074737548828\n",
      "Epoch 371: perda treino: 25.606727600097656\n",
      "Epoch 372: perda treino: 25.60638999938965\n",
      "Epoch 373: perda treino: 25.606048583984375\n",
      "Epoch 374: perda treino: 25.605709075927734\n",
      "Epoch 375: perda treino: 25.605377197265625\n",
      "Epoch 376: perda treino: 25.60504722595215\n",
      "Epoch 377: perda treino: 25.604713439941406\n",
      "Epoch 378: perda treino: 25.604385375976562\n",
      "Epoch 379: perda treino: 25.604066848754883\n",
      "Epoch 380: perda treino: 25.603748321533203\n",
      "Epoch 381: perda treino: 25.603425979614258\n",
      "Epoch 382: perda treino: 25.603113174438477\n",
      "Epoch 383: perda treino: 25.602800369262695\n",
      "Epoch 384: perda treino: 25.60249137878418\n",
      "Epoch 385: perda treino: 25.602191925048828\n",
      "Epoch 386: perda treino: 25.601884841918945\n",
      "Epoch 387: perda treino: 25.601587295532227\n",
      "Epoch 388: perda treino: 25.601295471191406\n",
      "Epoch 389: perda treino: 25.601001739501953\n",
      "Epoch 390: perda treino: 25.600706100463867\n",
      "Epoch 391: perda treino: 25.60041618347168\n",
      "Epoch 392: perda treino: 25.600128173828125\n",
      "Epoch 393: perda treino: 25.599842071533203\n",
      "Epoch 394: perda treino: 25.599563598632812\n",
      "Epoch 395: perda treino: 25.59928321838379\n",
      "Epoch 396: perda treino: 25.599002838134766\n",
      "Epoch 397: perda treino: 25.59872817993164\n",
      "Epoch 398: perda treino: 25.598453521728516\n",
      "Epoch 399: perda treino: 25.598182678222656\n",
      "Epoch 400: perda treino: 25.597911834716797\n",
      "Epoch 401: perda treino: 25.59764289855957\n",
      "Epoch 402: perda treino: 25.597373962402344\n",
      "Epoch 403: perda treino: 25.597116470336914\n",
      "Epoch 404: perda treino: 25.596847534179688\n",
      "Epoch 405: perda treino: 25.59658432006836\n",
      "Epoch 406: perda treino: 25.59632682800293\n",
      "Epoch 407: perda treino: 25.596073150634766\n",
      "Epoch 408: perda treino: 25.5958194732666\n",
      "Epoch 409: perda treino: 25.595565795898438\n",
      "Epoch 410: perda treino: 25.595314025878906\n",
      "Epoch 411: perda treino: 25.59506607055664\n",
      "Epoch 412: perda treino: 25.594816207885742\n",
      "Epoch 413: perda treino: 25.594573974609375\n",
      "Epoch 414: perda treino: 25.594331741333008\n",
      "Epoch 415: perda treino: 25.594083786010742\n",
      "Epoch 416: perda treino: 25.593847274780273\n",
      "Epoch 417: perda treino: 25.593608856201172\n",
      "Epoch 418: perda treino: 25.59337043762207\n",
      "Epoch 419: perda treino: 25.593137741088867\n",
      "Epoch 420: perda treino: 25.59290313720703\n",
      "Epoch 421: perda treino: 25.592670440673828\n",
      "Epoch 422: perda treino: 25.592437744140625\n",
      "Epoch 423: perda treino: 25.592208862304688\n",
      "Epoch 424: perda treino: 25.591981887817383\n",
      "Epoch 425: perda treino: 25.591754913330078\n",
      "Epoch 426: perda treino: 25.59153175354004\n",
      "Epoch 427: perda treino: 25.591306686401367\n",
      "Epoch 428: perda treino: 25.59108543395996\n",
      "Epoch 429: perda treino: 25.59086799621582\n",
      "Epoch 430: perda treino: 25.590646743774414\n",
      "Epoch 431: perda treino: 25.59043312072754\n",
      "Epoch 432: perda treino: 25.5902156829834\n",
      "Epoch 433: perda treino: 25.590003967285156\n",
      "Epoch 434: perda treino: 25.58979034423828\n",
      "Epoch 435: perda treino: 25.589582443237305\n",
      "Epoch 436: perda treino: 25.589370727539062\n",
      "Epoch 437: perda treino: 25.589162826538086\n",
      "Epoch 438: perda treino: 25.58895492553711\n",
      "Epoch 439: perda treino: 25.5887508392334\n",
      "Epoch 440: perda treino: 25.588544845581055\n",
      "Epoch 441: perda treino: 25.588340759277344\n",
      "Epoch 442: perda treino: 25.5881404876709\n",
      "Epoch 443: perda treino: 25.58793830871582\n",
      "Epoch 444: perda treino: 25.587743759155273\n",
      "Epoch 445: perda treino: 25.58754539489746\n",
      "Epoch 446: perda treino: 25.587350845336914\n",
      "Epoch 447: perda treino: 25.587156295776367\n",
      "Epoch 448: perda treino: 25.586963653564453\n",
      "Epoch 449: perda treino: 25.586769104003906\n",
      "Epoch 450: perda treino: 25.58658218383789\n",
      "Epoch 451: perda treino: 25.586393356323242\n",
      "Epoch 452: perda treino: 25.586204528808594\n",
      "Epoch 453: perda treino: 25.586017608642578\n",
      "Epoch 454: perda treino: 25.585832595825195\n",
      "Epoch 455: perda treino: 25.585647583007812\n",
      "Epoch 456: perda treino: 25.585466384887695\n",
      "Epoch 457: perda treino: 25.58527946472168\n",
      "Epoch 458: perda treino: 25.585102081298828\n",
      "Epoch 459: perda treino: 25.584924697875977\n",
      "Epoch 460: perda treino: 25.584745407104492\n",
      "Epoch 461: perda treino: 25.584569931030273\n",
      "Epoch 462: perda treino: 25.584392547607422\n",
      "Epoch 463: perda treino: 25.58422088623047\n",
      "Epoch 464: perda treino: 25.584049224853516\n",
      "Epoch 465: perda treino: 25.58387565612793\n",
      "Epoch 466: perda treino: 25.583707809448242\n",
      "Epoch 467: perda treino: 25.58353614807129\n",
      "Epoch 468: perda treino: 25.5833683013916\n",
      "Epoch 469: perda treino: 25.583200454711914\n",
      "Epoch 470: perda treino: 25.58305549621582\n",
      "Epoch 471: perda treino: 25.582897186279297\n",
      "Epoch 472: perda treino: 25.582733154296875\n",
      "Epoch 473: perda treino: 25.58258056640625\n",
      "Epoch 474: perda treino: 25.58244514465332\n",
      "Epoch 475: perda treino: 25.582300186157227\n",
      "Epoch 476: perda treino: 25.5821475982666\n",
      "Epoch 477: perda treino: 25.582002639770508\n",
      "Epoch 478: perda treino: 25.58186149597168\n",
      "Epoch 479: perda treino: 25.581724166870117\n",
      "Epoch 480: perda treino: 25.581588745117188\n",
      "Epoch 481: perda treino: 25.581457138061523\n",
      "Epoch 482: perda treino: 25.58131980895996\n",
      "Epoch 483: perda treino: 25.58119010925293\n",
      "Epoch 484: perda treino: 25.5810604095459\n",
      "Epoch 485: perda treino: 25.580934524536133\n",
      "Epoch 486: perda treino: 25.580808639526367\n",
      "Epoch 487: perda treino: 25.580686569213867\n",
      "Epoch 488: perda treino: 25.5805606842041\n",
      "Epoch 489: perda treino: 25.580440521240234\n",
      "Epoch 490: perda treino: 25.580318450927734\n",
      "Epoch 491: perda treino: 25.580204010009766\n",
      "Epoch 492: perda treino: 25.58008575439453\n",
      "Epoch 493: perda treino: 25.579973220825195\n",
      "Epoch 494: perda treino: 25.579856872558594\n",
      "Epoch 495: perda treino: 25.57973861694336\n",
      "Epoch 496: perda treino: 25.579626083374023\n",
      "Epoch 497: perda treino: 25.579513549804688\n",
      "Epoch 498: perda treino: 25.57940101623535\n",
      "Epoch 499: perda treino: 25.579294204711914\n",
      "Epoch 500: perda treino: 25.579185485839844\n",
      "Epoch 501: perda treino: 25.579078674316406\n",
      "Epoch 502: perda treino: 25.5789737701416\n",
      "Epoch 503: perda treino: 25.578866958618164\n",
      "Epoch 504: perda treino: 25.57876205444336\n",
      "Epoch 505: perda treino: 25.578659057617188\n",
      "Epoch 506: perda treino: 25.578554153442383\n",
      "Epoch 507: perda treino: 25.578453063964844\n",
      "Epoch 508: perda treino: 25.578353881835938\n",
      "Epoch 509: perda treino: 25.57825469970703\n",
      "Epoch 510: perda treino: 25.578155517578125\n",
      "Epoch 511: perda treino: 25.57805633544922\n",
      "Epoch 512: perda treino: 25.577960968017578\n",
      "Epoch 513: perda treino: 25.577863693237305\n",
      "Epoch 514: perda treino: 25.577768325805664\n",
      "Epoch 515: perda treino: 25.577672958374023\n",
      "Epoch 516: perda treino: 25.57758140563965\n",
      "Epoch 517: perda treino: 25.577489852905273\n",
      "Epoch 518: perda treino: 25.577396392822266\n",
      "Epoch 519: perda treino: 25.577306747436523\n",
      "Epoch 520: perda treino: 25.57721710205078\n",
      "Epoch 521: perda treino: 25.577125549316406\n",
      "Epoch 522: perda treino: 25.57703971862793\n",
      "Epoch 523: perda treino: 25.57695198059082\n",
      "Epoch 524: perda treino: 25.576862335205078\n",
      "Epoch 525: perda treino: 25.576778411865234\n",
      "Epoch 526: perda treino: 25.576690673828125\n",
      "Epoch 527: perda treino: 25.576608657836914\n",
      "Epoch 528: perda treino: 25.576526641845703\n",
      "Epoch 529: perda treino: 25.576440811157227\n",
      "Epoch 530: perda treino: 25.576358795166016\n",
      "Epoch 531: perda treino: 25.576278686523438\n",
      "Epoch 532: perda treino: 25.576196670532227\n",
      "Epoch 533: perda treino: 25.57611846923828\n",
      "Epoch 534: perda treino: 25.576038360595703\n",
      "Epoch 535: perda treino: 25.575958251953125\n",
      "Epoch 536: perda treino: 25.575881958007812\n",
      "Epoch 537: perda treino: 25.575801849365234\n",
      "Epoch 538: perda treino: 25.575727462768555\n",
      "Epoch 539: perda treino: 25.575651168823242\n",
      "Epoch 540: perda treino: 25.575576782226562\n",
      "Epoch 541: perda treino: 25.57550048828125\n",
      "Epoch 542: perda treino: 25.57542610168457\n",
      "Epoch 543: perda treino: 25.575353622436523\n",
      "Epoch 544: perda treino: 25.575284957885742\n",
      "Epoch 545: perda treino: 25.575210571289062\n",
      "Epoch 546: perda treino: 25.57513999938965\n",
      "Epoch 547: perda treino: 25.575069427490234\n",
      "Epoch 548: perda treino: 25.575000762939453\n",
      "Epoch 549: perda treino: 25.574932098388672\n",
      "Epoch 550: perda treino: 25.574861526489258\n",
      "Epoch 551: perda treino: 25.574796676635742\n",
      "Epoch 552: perda treino: 25.574729919433594\n",
      "Epoch 553: perda treino: 25.574663162231445\n",
      "Epoch 554: perda treino: 25.574594497680664\n",
      "Epoch 555: perda treino: 25.574527740478516\n",
      "Epoch 556: perda treino: 25.5744686126709\n",
      "Epoch 557: perda treino: 25.574399948120117\n",
      "Epoch 558: perda treino: 25.574337005615234\n",
      "Epoch 559: perda treino: 25.574275970458984\n",
      "Epoch 560: perda treino: 25.5742130279541\n",
      "Epoch 561: perda treino: 25.574153900146484\n",
      "Epoch 562: perda treino: 25.5740909576416\n",
      "Epoch 563: perda treino: 25.57402992248535\n",
      "Epoch 564: perda treino: 25.573970794677734\n",
      "Epoch 565: perda treino: 25.573911666870117\n",
      "Epoch 566: perda treino: 25.573854446411133\n",
      "Epoch 567: perda treino: 25.57379722595215\n",
      "Epoch 568: perda treino: 25.57373809814453\n",
      "Epoch 569: perda treino: 25.573680877685547\n",
      "Epoch 570: perda treino: 25.573623657226562\n",
      "Epoch 571: perda treino: 25.573566436767578\n",
      "Epoch 572: perda treino: 25.57351303100586\n",
      "Epoch 573: perda treino: 25.573457717895508\n",
      "Epoch 574: perda treino: 25.57340431213379\n",
      "Epoch 575: perda treino: 25.573348999023438\n",
      "Epoch 576: perda treino: 25.57329750061035\n",
      "Epoch 577: perda treino: 25.573244094848633\n",
      "Epoch 578: perda treino: 25.573190689086914\n",
      "Epoch 579: perda treino: 25.573139190673828\n",
      "Epoch 580: perda treino: 25.57308578491211\n",
      "Epoch 581: perda treino: 25.57303810119629\n",
      "Epoch 582: perda treino: 25.572986602783203\n",
      "Epoch 583: perda treino: 25.572938919067383\n",
      "Epoch 584: perda treino: 25.57288932800293\n",
      "Epoch 585: perda treino: 25.572843551635742\n",
      "Epoch 586: perda treino: 25.572795867919922\n",
      "Epoch 587: perda treino: 25.572744369506836\n",
      "Epoch 588: perda treino: 25.57269859313965\n",
      "Epoch 589: perda treino: 25.572650909423828\n",
      "Epoch 590: perda treino: 25.572607040405273\n",
      "Epoch 591: perda treino: 25.57255744934082\n",
      "Epoch 592: perda treino: 25.572513580322266\n",
      "Epoch 593: perda treino: 25.572465896606445\n",
      "Epoch 594: perda treino: 25.57242202758789\n",
      "Epoch 595: perda treino: 25.57238006591797\n",
      "Epoch 596: perda treino: 25.572336196899414\n",
      "Epoch 597: perda treino: 25.57229232788086\n",
      "Epoch 598: perda treino: 25.572250366210938\n",
      "Epoch 599: perda treino: 25.572206497192383\n",
      "Epoch 600: perda treino: 25.57216453552246\n",
      "Epoch 601: perda treino: 25.57212257385254\n",
      "Epoch 602: perda treino: 25.57208251953125\n",
      "Epoch 603: perda treino: 25.572044372558594\n",
      "Epoch 604: perda treino: 25.572002410888672\n",
      "Epoch 605: perda treino: 25.571964263916016\n",
      "Epoch 606: perda treino: 25.571924209594727\n",
      "Epoch 607: perda treino: 25.571882247924805\n",
      "Epoch 608: perda treino: 25.57184410095215\n",
      "Epoch 609: perda treino: 25.571805953979492\n",
      "Epoch 610: perda treino: 25.571767807006836\n",
      "Epoch 611: perda treino: 25.57172966003418\n",
      "Epoch 612: perda treino: 25.571693420410156\n",
      "Epoch 613: perda treino: 25.571657180786133\n",
      "Epoch 614: perda treino: 25.571622848510742\n",
      "Epoch 615: perda treino: 25.571584701538086\n",
      "Epoch 616: perda treino: 25.571550369262695\n",
      "Epoch 617: perda treino: 25.57151222229004\n",
      "Epoch 618: perda treino: 25.57147979736328\n",
      "Epoch 619: perda treino: 25.571447372436523\n",
      "Epoch 620: perda treino: 25.5714111328125\n",
      "Epoch 621: perda treino: 25.571378707885742\n",
      "Epoch 622: perda treino: 25.57134437561035\n",
      "Epoch 623: perda treino: 25.57131004333496\n",
      "Epoch 624: perda treino: 25.571277618408203\n",
      "Epoch 625: perda treino: 25.571245193481445\n",
      "Epoch 626: perda treino: 25.57121467590332\n",
      "Epoch 627: perda treino: 25.571182250976562\n",
      "Epoch 628: perda treino: 25.571147918701172\n",
      "Epoch 629: perda treino: 25.57111930847168\n",
      "Epoch 630: perda treino: 25.571086883544922\n",
      "Epoch 631: perda treino: 25.571056365966797\n",
      "Epoch 632: perda treino: 25.571025848388672\n",
      "Epoch 633: perda treino: 25.570995330810547\n",
      "Epoch 634: perda treino: 25.57096290588379\n",
      "Epoch 635: perda treino: 25.570932388305664\n",
      "Epoch 636: perda treino: 25.570905685424805\n",
      "Epoch 637: perda treino: 25.570877075195312\n",
      "Epoch 638: perda treino: 25.570846557617188\n",
      "Epoch 639: perda treino: 25.570819854736328\n",
      "Epoch 640: perda treino: 25.570791244506836\n",
      "Epoch 641: perda treino: 25.570764541625977\n",
      "Epoch 642: perda treino: 25.570737838745117\n",
      "Epoch 643: perda treino: 25.57071304321289\n",
      "Epoch 644: perda treino: 25.5706844329834\n",
      "Epoch 645: perda treino: 25.57065773010254\n",
      "Epoch 646: perda treino: 25.57063102722168\n",
      "Epoch 647: perda treino: 25.570606231689453\n",
      "Epoch 648: perda treino: 25.57057762145996\n",
      "Epoch 649: perda treino: 25.570552825927734\n",
      "Epoch 650: perda treino: 25.570524215698242\n",
      "Epoch 651: perda treino: 25.57050132751465\n",
      "Epoch 652: perda treino: 25.570472717285156\n",
      "Epoch 653: perda treino: 25.570449829101562\n",
      "Epoch 654: perda treino: 25.57042694091797\n",
      "Epoch 655: perda treino: 25.570402145385742\n",
      "Epoch 656: perda treino: 25.570377349853516\n",
      "Epoch 657: perda treino: 25.57035255432129\n",
      "Epoch 658: perda treino: 25.570329666137695\n",
      "Epoch 659: perda treino: 25.57030487060547\n",
      "Epoch 660: perda treino: 25.570283889770508\n",
      "Epoch 661: perda treino: 25.570261001586914\n",
      "Epoch 662: perda treino: 25.570240020751953\n",
      "Epoch 663: perda treino: 25.570215225219727\n",
      "Epoch 664: perda treino: 25.570194244384766\n",
      "Epoch 665: perda treino: 25.570171356201172\n",
      "Epoch 666: perda treino: 25.57015037536621\n",
      "Epoch 667: perda treino: 25.57012939453125\n",
      "Epoch 668: perda treino: 25.57010841369629\n",
      "Epoch 669: perda treino: 25.570087432861328\n",
      "Epoch 670: perda treino: 25.570066452026367\n",
      "Epoch 671: perda treino: 25.570043563842773\n",
      "Epoch 672: perda treino: 25.570022583007812\n",
      "Epoch 673: perda treino: 25.570003509521484\n",
      "Epoch 674: perda treino: 25.569982528686523\n",
      "Epoch 675: perda treino: 25.569963455200195\n",
      "Epoch 676: perda treino: 25.569942474365234\n",
      "Epoch 677: perda treino: 25.56992530822754\n",
      "Epoch 678: perda treino: 25.569900512695312\n",
      "Epoch 679: perda treino: 25.569883346557617\n",
      "Epoch 680: perda treino: 25.569862365722656\n",
      "Epoch 681: perda treino: 25.569843292236328\n",
      "Epoch 682: perda treino: 25.56982421875\n",
      "Epoch 683: perda treino: 25.569807052612305\n",
      "Epoch 684: perda treino: 25.569787979125977\n",
      "Epoch 685: perda treino: 25.56977081298828\n",
      "Epoch 686: perda treino: 25.56974983215332\n",
      "Epoch 687: perda treino: 25.56973648071289\n",
      "Epoch 688: perda treino: 25.56971549987793\n",
      "Epoch 689: perda treino: 25.569700241088867\n",
      "Epoch 690: perda treino: 25.569683074951172\n",
      "Epoch 691: perda treino: 25.569665908813477\n",
      "Epoch 692: perda treino: 25.569650650024414\n",
      "Epoch 693: perda treino: 25.569631576538086\n",
      "Epoch 694: perda treino: 25.569616317749023\n",
      "Epoch 695: perda treino: 25.569595336914062\n",
      "Epoch 696: perda treino: 25.569580078125\n",
      "Epoch 697: perda treino: 25.569562911987305\n",
      "Epoch 698: perda treino: 25.56954574584961\n",
      "Epoch 699: perda treino: 25.569530487060547\n",
      "Epoch 700: perda treino: 25.56951332092285\n",
      "Epoch 701: perda treino: 25.56949806213379\n",
      "Epoch 702: perda treino: 25.569482803344727\n",
      "Epoch 703: perda treino: 25.56946563720703\n",
      "Epoch 704: perda treino: 25.56945037841797\n",
      "Epoch 705: perda treino: 25.569433212280273\n",
      "Epoch 706: perda treino: 25.569419860839844\n",
      "Epoch 707: perda treino: 25.569406509399414\n",
      "Epoch 708: perda treino: 25.569393157958984\n",
      "Epoch 709: perda treino: 25.56937599182129\n",
      "Epoch 710: perda treino: 25.56936264038086\n",
      "Epoch 711: perda treino: 25.56934928894043\n",
      "Epoch 712: perda treino: 25.569332122802734\n",
      "Epoch 713: perda treino: 25.569316864013672\n",
      "Epoch 714: perda treino: 25.569303512573242\n",
      "Epoch 715: perda treino: 25.569290161132812\n",
      "Epoch 716: perda treino: 25.569276809692383\n",
      "Epoch 717: perda treino: 25.569263458251953\n",
      "Epoch 718: perda treino: 25.56924819946289\n",
      "Epoch 719: perda treino: 25.569232940673828\n",
      "Epoch 720: perda treino: 25.56922149658203\n",
      "Epoch 721: perda treino: 25.5692081451416\n",
      "Epoch 722: perda treino: 25.569194793701172\n",
      "Epoch 723: perda treino: 25.56917953491211\n",
      "Epoch 724: perda treino: 25.56916618347168\n",
      "Epoch 725: perda treino: 25.569154739379883\n",
      "Epoch 726: perda treino: 25.569143295288086\n",
      "Epoch 727: perda treino: 25.569128036499023\n",
      "Epoch 728: perda treino: 25.569116592407227\n",
      "Epoch 729: perda treino: 25.56910514831543\n",
      "Epoch 730: perda treino: 25.569089889526367\n",
      "Epoch 731: perda treino: 25.56907844543457\n",
      "Epoch 732: perda treino: 25.56906509399414\n",
      "Epoch 733: perda treino: 25.569053649902344\n",
      "Epoch 734: perda treino: 25.569042205810547\n",
      "Epoch 735: perda treino: 25.569026947021484\n",
      "Epoch 736: perda treino: 25.56901741027832\n",
      "Epoch 737: perda treino: 25.569007873535156\n",
      "Epoch 738: perda treino: 25.568992614746094\n",
      "Epoch 739: perda treino: 25.568981170654297\n",
      "Epoch 740: perda treino: 25.568971633911133\n",
      "Epoch 741: perda treino: 25.568958282470703\n",
      "Epoch 742: perda treino: 25.568946838378906\n",
      "Epoch 743: perda treino: 25.568937301635742\n",
      "Epoch 744: perda treino: 25.568927764892578\n",
      "Epoch 745: perda treino: 25.568918228149414\n",
      "Epoch 746: perda treino: 25.568906784057617\n",
      "Epoch 747: perda treino: 25.568893432617188\n",
      "Epoch 748: perda treino: 25.56888198852539\n",
      "Epoch 749: perda treino: 25.568872451782227\n",
      "Epoch 750: perda treino: 25.56886100769043\n",
      "Epoch 751: perda treino: 25.568849563598633\n",
      "Epoch 752: perda treino: 25.568838119506836\n",
      "Epoch 753: perda treino: 25.568828582763672\n",
      "Epoch 754: perda treino: 25.568817138671875\n",
      "Epoch 755: perda treino: 25.568805694580078\n",
      "Epoch 756: perda treino: 25.568796157836914\n",
      "Epoch 757: perda treino: 25.56878662109375\n",
      "Epoch 758: perda treino: 25.568777084350586\n",
      "Epoch 759: perda treino: 25.568767547607422\n",
      "Epoch 760: perda treino: 25.568758010864258\n",
      "Epoch 761: perda treino: 25.568744659423828\n",
      "Epoch 762: perda treino: 25.56873893737793\n",
      "Epoch 763: perda treino: 25.568727493286133\n",
      "Epoch 764: perda treino: 25.56871795654297\n",
      "Epoch 765: perda treino: 25.568710327148438\n",
      "Epoch 766: perda treino: 25.56869888305664\n",
      "Epoch 767: perda treino: 25.568689346313477\n",
      "Epoch 768: perda treino: 25.568679809570312\n",
      "Epoch 769: perda treino: 25.56867218017578\n",
      "Epoch 770: perda treino: 25.56866455078125\n",
      "Epoch 771: perda treino: 25.568653106689453\n",
      "Epoch 772: perda treino: 25.568645477294922\n",
      "Epoch 773: perda treino: 25.568635940551758\n",
      "Epoch 774: perda treino: 25.568628311157227\n",
      "Epoch 775: perda treino: 25.568618774414062\n",
      "Epoch 776: perda treino: 25.56861114501953\n",
      "Epoch 777: perda treino: 25.568601608276367\n",
      "Epoch 778: perda treino: 25.56859016418457\n",
      "Epoch 779: perda treino: 25.568584442138672\n",
      "Epoch 780: perda treino: 25.568572998046875\n",
      "Epoch 781: perda treino: 25.568567276000977\n",
      "Epoch 782: perda treino: 25.56855583190918\n",
      "Epoch 783: perda treino: 25.56855010986328\n",
      "Epoch 784: perda treino: 25.568540573120117\n",
      "Epoch 785: perda treino: 25.568532943725586\n",
      "Epoch 786: perda treino: 25.56852149963379\n",
      "Epoch 787: perda treino: 25.56851577758789\n",
      "Epoch 788: perda treino: 25.568506240844727\n",
      "Epoch 789: perda treino: 25.568500518798828\n",
      "Epoch 790: perda treino: 25.568490982055664\n",
      "Epoch 791: perda treino: 25.568483352661133\n",
      "Epoch 792: perda treino: 25.56847381591797\n",
      "Epoch 793: perda treino: 25.568466186523438\n",
      "Epoch 794: perda treino: 25.56846046447754\n",
      "Epoch 795: perda treino: 25.568450927734375\n",
      "Epoch 796: perda treino: 25.568443298339844\n",
      "Epoch 797: perda treino: 25.568435668945312\n",
      "Epoch 798: perda treino: 25.568429946899414\n",
      "Epoch 799: perda treino: 25.568422317504883\n",
      "Epoch 800: perda treino: 25.56841468811035\n",
      "Epoch 801: perda treino: 25.56840705871582\n",
      "Epoch 802: perda treino: 25.56839942932129\n",
      "Epoch 803: perda treino: 25.568391799926758\n",
      "Epoch 804: perda treino: 25.56838607788086\n",
      "Epoch 805: perda treino: 25.568378448486328\n",
      "Epoch 806: perda treino: 25.568370819091797\n",
      "Epoch 807: perda treino: 25.5683650970459\n",
      "Epoch 808: perda treino: 25.568359375\n",
      "Epoch 809: perda treino: 25.568347930908203\n",
      "Epoch 810: perda treino: 25.568340301513672\n",
      "Epoch 811: perda treino: 25.568334579467773\n",
      "Epoch 812: perda treino: 25.568330764770508\n",
      "Epoch 813: perda treino: 25.568321228027344\n",
      "Epoch 814: perda treino: 25.568313598632812\n",
      "Epoch 815: perda treino: 25.56830596923828\n",
      "Epoch 816: perda treino: 25.56829833984375\n",
      "Epoch 817: perda treino: 25.568294525146484\n",
      "Epoch 818: perda treino: 25.568286895751953\n",
      "Epoch 819: perda treino: 25.568281173706055\n",
      "Epoch 820: perda treino: 25.568275451660156\n",
      "Epoch 821: perda treino: 25.568267822265625\n",
      "Epoch 822: perda treino: 25.568262100219727\n",
      "Epoch 823: perda treino: 25.568254470825195\n",
      "Epoch 824: perda treino: 25.568246841430664\n",
      "Epoch 825: perda treino: 25.5682430267334\n",
      "Epoch 826: perda treino: 25.5682373046875\n",
      "Epoch 827: perda treino: 25.56822967529297\n",
      "Epoch 828: perda treino: 25.56822395324707\n",
      "Epoch 829: perda treino: 25.56821632385254\n",
      "Epoch 830: perda treino: 25.568212509155273\n",
      "Epoch 831: perda treino: 25.568206787109375\n",
      "Epoch 832: perda treino: 25.568199157714844\n",
      "Epoch 833: perda treino: 25.568195343017578\n",
      "Epoch 834: perda treino: 25.568187713623047\n",
      "Epoch 835: perda treino: 25.56818199157715\n",
      "Epoch 836: perda treino: 25.568178176879883\n",
      "Epoch 837: perda treino: 25.568172454833984\n",
      "Epoch 838: perda treino: 25.568164825439453\n",
      "Epoch 839: perda treino: 25.568159103393555\n",
      "Epoch 840: perda treino: 25.568151473999023\n",
      "Epoch 841: perda treino: 25.568147659301758\n",
      "Epoch 842: perda treino: 25.56814193725586\n",
      "Epoch 843: perda treino: 25.568134307861328\n",
      "Epoch 844: perda treino: 25.568130493164062\n",
      "Epoch 845: perda treino: 25.568124771118164\n",
      "Epoch 846: perda treino: 25.568117141723633\n",
      "Epoch 847: perda treino: 25.568113327026367\n",
      "Epoch 848: perda treino: 25.56810760498047\n",
      "Epoch 849: perda treino: 25.568099975585938\n",
      "Epoch 850: perda treino: 25.568096160888672\n",
      "Epoch 851: perda treino: 25.568092346191406\n",
      "Epoch 852: perda treino: 25.568086624145508\n",
      "Epoch 853: perda treino: 25.568078994750977\n",
      "Epoch 854: perda treino: 25.56807518005371\n",
      "Epoch 855: perda treino: 25.568069458007812\n",
      "Epoch 856: perda treino: 25.568063735961914\n",
      "Epoch 857: perda treino: 25.56805992126465\n",
      "Epoch 858: perda treino: 25.568056106567383\n",
      "Epoch 859: perda treino: 25.568050384521484\n",
      "Epoch 860: perda treino: 25.568044662475586\n",
      "Epoch 861: perda treino: 25.56804084777832\n",
      "Epoch 862: perda treino: 25.568035125732422\n",
      "Epoch 863: perda treino: 25.568029403686523\n",
      "Epoch 864: perda treino: 25.568025588989258\n",
      "Epoch 865: perda treino: 25.568021774291992\n",
      "Epoch 866: perda treino: 25.56801414489746\n",
      "Epoch 867: perda treino: 25.568012237548828\n",
      "Epoch 868: perda treino: 25.568008422851562\n",
      "Epoch 869: perda treino: 25.56800079345703\n",
      "Epoch 870: perda treino: 25.567995071411133\n",
      "Epoch 871: perda treino: 25.567991256713867\n",
      "Epoch 872: perda treino: 25.5679874420166\n",
      "Epoch 873: perda treino: 25.567983627319336\n",
      "Epoch 874: perda treino: 25.567975997924805\n",
      "Epoch 875: perda treino: 25.567974090576172\n",
      "Epoch 876: perda treino: 25.56796646118164\n",
      "Epoch 877: perda treino: 25.567962646484375\n",
      "Epoch 878: perda treino: 25.56795883178711\n",
      "Epoch 879: perda treino: 25.567955017089844\n",
      "Epoch 880: perda treino: 25.567951202392578\n",
      "Epoch 881: perda treino: 25.56794548034668\n",
      "Epoch 882: perda treino: 25.567941665649414\n",
      "Epoch 883: perda treino: 25.56793785095215\n",
      "Epoch 884: perda treino: 25.56793212890625\n",
      "Epoch 885: perda treino: 25.567928314208984\n",
      "Epoch 886: perda treino: 25.56792449951172\n",
      "Epoch 887: perda treino: 25.56791877746582\n",
      "Epoch 888: perda treino: 25.567914962768555\n",
      "Epoch 889: perda treino: 25.56791114807129\n",
      "Epoch 890: perda treino: 25.56790542602539\n",
      "Epoch 891: perda treino: 25.567901611328125\n",
      "Epoch 892: perda treino: 25.56789779663086\n",
      "Epoch 893: perda treino: 25.567895889282227\n",
      "Epoch 894: perda treino: 25.567890167236328\n",
      "Epoch 895: perda treino: 25.567886352539062\n",
      "Epoch 896: perda treino: 25.567882537841797\n",
      "Epoch 897: perda treino: 25.56787872314453\n",
      "Epoch 898: perda treino: 25.567873001098633\n",
      "Epoch 899: perda treino: 25.56787109375\n",
      "Epoch 900: perda treino: 25.567867279052734\n",
      "Epoch 901: perda treino: 25.56786346435547\n",
      "Epoch 902: perda treino: 25.56786346435547\n",
      "Epoch 903: perda treino: 25.567855834960938\n",
      "Epoch 904: perda treino: 25.567853927612305\n",
      "Epoch 905: perda treino: 25.56785011291504\n",
      "Epoch 906: perda treino: 25.567846298217773\n",
      "Epoch 907: perda treino: 25.567842483520508\n",
      "Epoch 908: perda treino: 25.567838668823242\n",
      "Epoch 909: perda treino: 25.567834854125977\n",
      "Epoch 910: perda treino: 25.56783103942871\n",
      "Epoch 911: perda treino: 25.567827224731445\n",
      "Epoch 912: perda treino: 25.56782341003418\n",
      "Epoch 913: perda treino: 25.567819595336914\n",
      "Epoch 914: perda treino: 25.56781768798828\n",
      "Epoch 915: perda treino: 25.567811965942383\n",
      "Epoch 916: perda treino: 25.56781005859375\n",
      "Epoch 917: perda treino: 25.56780433654785\n",
      "Epoch 918: perda treino: 25.56780242919922\n",
      "Epoch 919: perda treino: 25.567798614501953\n",
      "Epoch 920: perda treino: 25.567790985107422\n",
      "Epoch 921: perda treino: 25.567787170410156\n",
      "Epoch 922: perda treino: 25.567787170410156\n",
      "Epoch 923: perda treino: 25.56778335571289\n",
      "Epoch 924: perda treino: 25.567779541015625\n",
      "Epoch 925: perda treino: 25.567777633666992\n",
      "Epoch 926: perda treino: 25.567771911621094\n",
      "Epoch 927: perda treino: 25.56777000427246\n",
      "Epoch 928: perda treino: 25.567766189575195\n",
      "Epoch 929: perda treino: 25.567764282226562\n",
      "Epoch 930: perda treino: 25.56776237487793\n",
      "Epoch 931: perda treino: 25.56775665283203\n",
      "Epoch 932: perda treino: 25.567752838134766\n",
      "Epoch 933: perda treino: 25.567752838134766\n",
      "Epoch 934: perda treino: 25.567747116088867\n",
      "Epoch 935: perda treino: 25.5677433013916\n",
      "Epoch 936: perda treino: 25.56774139404297\n",
      "Epoch 937: perda treino: 25.567737579345703\n",
      "Epoch 938: perda treino: 25.56773567199707\n",
      "Epoch 939: perda treino: 25.567733764648438\n",
      "Epoch 940: perda treino: 25.567729949951172\n",
      "Epoch 941: perda treino: 25.567726135253906\n",
      "Epoch 942: perda treino: 25.567726135253906\n",
      "Epoch 943: perda treino: 25.56772232055664\n",
      "Epoch 944: perda treino: 25.567720413208008\n",
      "Epoch 945: perda treino: 25.567716598510742\n",
      "Epoch 946: perda treino: 25.56771469116211\n",
      "Epoch 947: perda treino: 25.56770896911621\n",
      "Epoch 948: perda treino: 25.567705154418945\n",
      "Epoch 949: perda treino: 25.567705154418945\n",
      "Epoch 950: perda treino: 25.567703247070312\n",
      "Epoch 951: perda treino: 25.567697525024414\n",
      "Epoch 952: perda treino: 25.56769371032715\n",
      "Epoch 953: perda treino: 25.567689895629883\n",
      "Epoch 954: perda treino: 25.56768798828125\n",
      "Epoch 955: perda treino: 25.567686080932617\n",
      "Epoch 956: perda treino: 25.56768226623535\n",
      "Epoch 957: perda treino: 25.56768035888672\n",
      "Epoch 958: perda treino: 25.56768035888672\n",
      "Epoch 959: perda treino: 25.56767463684082\n",
      "Epoch 960: perda treino: 25.567672729492188\n",
      "Epoch 961: perda treino: 25.567668914794922\n",
      "Epoch 962: perda treino: 25.567668914794922\n",
      "Epoch 963: perda treino: 25.567668914794922\n",
      "Epoch 964: perda treino: 25.56766128540039\n",
      "Epoch 965: perda treino: 25.567657470703125\n",
      "Epoch 966: perda treino: 25.567657470703125\n",
      "Epoch 967: perda treino: 25.56765365600586\n",
      "Epoch 968: perda treino: 25.567651748657227\n",
      "Epoch 969: perda treino: 25.567651748657227\n",
      "Epoch 970: perda treino: 25.567646026611328\n",
      "Epoch 971: perda treino: 25.567644119262695\n",
      "Epoch 972: perda treino: 25.567642211914062\n",
      "Epoch 973: perda treino: 25.56764030456543\n",
      "Epoch 974: perda treino: 25.567636489868164\n",
      "Epoch 975: perda treino: 25.56763458251953\n",
      "Epoch 976: perda treino: 25.567630767822266\n",
      "Epoch 977: perda treino: 25.567630767822266\n",
      "Epoch 978: perda treino: 25.567626953125\n",
      "Epoch 979: perda treino: 25.567625045776367\n",
      "Epoch 980: perda treino: 25.567623138427734\n",
      "Epoch 981: perda treino: 25.56761932373047\n",
      "Epoch 982: perda treino: 25.567617416381836\n",
      "Epoch 983: perda treino: 25.567617416381836\n",
      "Epoch 984: perda treino: 25.567617416381836\n",
      "Epoch 985: perda treino: 25.56761360168457\n",
      "Epoch 986: perda treino: 25.567609786987305\n",
      "Epoch 987: perda treino: 25.56760597229004\n",
      "Epoch 988: perda treino: 25.567607879638672\n",
      "Epoch 989: perda treino: 25.567602157592773\n",
      "Epoch 990: perda treino: 25.56760025024414\n",
      "Epoch 991: perda treino: 25.56760025024414\n",
      "Epoch 992: perda treino: 25.567598342895508\n",
      "Epoch 993: perda treino: 25.56759262084961\n",
      "Epoch 994: perda treino: 25.56759262084961\n",
      "Epoch 995: perda treino: 25.56759262084961\n",
      "Epoch 996: perda treino: 25.567588806152344\n",
      "Epoch 997: perda treino: 25.567584991455078\n",
      "Epoch 998: perda treino: 25.567583084106445\n",
      "Epoch 999: perda treino: 25.567583084106445\n",
      "Teste - perda depois do treinamento 27.524208068847656\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Feedforward(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            \n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc4 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            \n",
    "            \n",
    "        def forward(self, x):\n",
    "            output = self.fc1(x)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc2(output)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc3(output)\n",
    "            output = self.relu(output)\n",
    "\n",
    "            output = self.fc4(output)\n",
    "\n",
    "            return output\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dfCarros = pd.read_csv('datasetCarros.csv')\n",
    "\n",
    "dfCarros.replace({'TipoCombustivel':{'Petrol':0,'Diesel':1,'CNG':2}},inplace=True)\n",
    "dfCarros.replace({'Trasmissao':{'Manual':0,'Automatic':1}},inplace=True)\n",
    "\n",
    "\n",
    "y= dfCarros['PrecoVenda']\n",
    "X = dfCarros.drop(['Nome','PrecoVenda'],axis=1)\n",
    "\n",
    "\n",
    "y_tensor = torch.tensor(y)\n",
    "X_tensor = torch.tensor(X.to_numpy())\n",
    "print(y_tensor.shape)\n",
    "print(X_tensor.shape)\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X_tensor, y_tensor, test_size = 0.10, random_state=5)\n",
    "\n",
    "print(X_treino.shape)\n",
    "print(y_treino.shape)\n",
    "\n",
    "X_treino = X_treino.float().to(device)\n",
    "y_treino = y_treino.float().to(device)\n",
    "\n",
    "X_teste = X_teste.float().to(device)\n",
    "y_teste = y_teste.float().to(device)\n",
    "\n",
    "\n",
    "model = Feedforward(6, 20).to(device)\n",
    "print(model)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "y_pred = model(X_teste)\n",
    "antes_treino = criterion(y_pred, y_teste) \n",
    "print('Teste - perda antes do treinamento' , antes_treino.item())\n",
    "\n",
    "model.train()\n",
    "epoch = 1000\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Passe Forward\n",
    "    y_pred = model(X_treino)\n",
    "    \n",
    "    # Computa a perda\n",
    "    loss = criterion(y_pred, y_treino)\n",
    "    \n",
    "    print('Epoch {}: perda treino: {}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # Passe de Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "model.eval()\n",
    "y_pred = model(X_teste)\n",
    "after_train = criterion(y_pred, y_teste) \n",
    "print('Teste - perda depois do treinamento' , after_train.item())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
